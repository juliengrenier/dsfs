{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 49, 4, 0],\n",
       " [1, 41, 9, 0],\n",
       " [1, 40, 8, 0],\n",
       " [1, 25, 6, 0],\n",
       " [1, 21, 1, 0],\n",
       " [1, 21, 0, 0],\n",
       " [1, 19, 3, 0],\n",
       " [1, 19, 0, 0],\n",
       " [1, 18, 9, 0],\n",
       " [1, 18, 8, 0],\n",
       " [1, 16, 4, 0],\n",
       " [1, 15, 3, 0],\n",
       " [1, 15, 0, 0],\n",
       " [1, 15, 2, 0],\n",
       " [1, 15, 7, 0],\n",
       " [1, 14, 0, 0],\n",
       " [1, 14, 1, 0],\n",
       " [1, 13, 1, 0],\n",
       " [1, 13, 7, 0],\n",
       " [1, 13, 4, 0],\n",
       " [1, 13, 2, 0],\n",
       " [1, 12, 5, 0],\n",
       " [1, 12, 0, 0],\n",
       " [1, 11, 9, 0],\n",
       " [1, 10, 9, 0],\n",
       " [1, 10, 1, 0],\n",
       " [1, 10, 1, 0],\n",
       " [1, 10, 7, 0],\n",
       " [1, 10, 9, 0],\n",
       " [1, 10, 1, 0],\n",
       " [1, 10, 6, 0],\n",
       " [1, 10, 6, 0],\n",
       " [1, 10, 8, 0],\n",
       " [1, 10, 10, 0],\n",
       " [1, 10, 6, 0],\n",
       " [1, 10, 0, 0],\n",
       " [1, 10, 5, 0],\n",
       " [1, 10, 3, 0],\n",
       " [1, 10, 4, 0],\n",
       " [1, 9, 9, 0],\n",
       " [1, 9, 9, 0],\n",
       " [1, 9, 0, 0],\n",
       " [1, 9, 0, 0],\n",
       " [1, 9, 6, 0],\n",
       " [1, 9, 10, 0],\n",
       " [1, 9, 8, 0],\n",
       " [1, 9, 5, 0],\n",
       " [1, 9, 2, 0],\n",
       " [1, 9, 9, 0],\n",
       " [1, 9, 10, 0],\n",
       " [1, 9, 7, 0],\n",
       " [1, 9, 2, 0],\n",
       " [1, 9, 0, 0],\n",
       " [1, 9, 4, 0],\n",
       " [1, 9, 6, 0],\n",
       " [1, 9, 4, 0],\n",
       " [1, 9, 7, 0],\n",
       " [1, 8, 3, 0],\n",
       " [1, 8, 2, 0],\n",
       " [1, 8, 4, 0],\n",
       " [1, 8, 9, 0],\n",
       " [1, 8, 2, 0],\n",
       " [1, 8, 3, 0],\n",
       " [1, 8, 5, 0],\n",
       " [1, 8, 8, 0],\n",
       " [1, 8, 0, 0],\n",
       " [1, 8, 9, 0],\n",
       " [1, 8, 10, 0],\n",
       " [1, 8, 5, 0],\n",
       " [1, 8, 5, 0],\n",
       " [1, 7, 5, 0],\n",
       " [1, 7, 5, 0],\n",
       " [1, 7, 0, 0],\n",
       " [1, 7, 2, 0],\n",
       " [1, 7, 8, 0],\n",
       " [1, 7, 10, 0],\n",
       " [1, 7, 5, 0],\n",
       " [1, 7, 3, 0],\n",
       " [1, 7, 3, 0],\n",
       " [1, 7, 6, 0],\n",
       " [1, 7, 7, 0],\n",
       " [1, 7, 7, 0],\n",
       " [1, 7, 9, 0],\n",
       " [1, 7, 3, 0],\n",
       " [1, 7, 8, 0],\n",
       " [1, 6, 4, 0],\n",
       " [1, 6, 6, 0],\n",
       " [1, 6, 4, 0],\n",
       " [1, 6, 9, 0],\n",
       " [1, 6, 0, 0],\n",
       " [1, 6, 1, 0],\n",
       " [1, 6, 4, 0],\n",
       " [1, 6, 1, 0],\n",
       " [1, 6, 0, 0],\n",
       " [1, 6, 7, 0],\n",
       " [1, 6, 0, 0],\n",
       " [1, 6, 8, 0],\n",
       " [1, 6, 4, 0],\n",
       " [1, 6, 2, 1],\n",
       " [1, 6, 1, 1],\n",
       " [1, 6, 3, 1],\n",
       " [1, 6, 6, 1],\n",
       " [1, 6, 4, 1],\n",
       " [1, 6, 4, 1],\n",
       " [1, 6, 1, 1],\n",
       " [1, 6, 3, 1],\n",
       " [1, 6, 4, 1],\n",
       " [1, 5, 1, 1],\n",
       " [1, 5, 9, 1],\n",
       " [1, 5, 4, 1],\n",
       " [1, 5, 6, 1],\n",
       " [1, 5, 4, 1],\n",
       " [1, 5, 4, 1],\n",
       " [1, 5, 10, 1],\n",
       " [1, 5, 5, 1],\n",
       " [1, 5, 2, 1],\n",
       " [1, 5, 4, 1],\n",
       " [1, 5, 4, 1],\n",
       " [1, 5, 9, 1],\n",
       " [1, 5, 3, 1],\n",
       " [1, 5, 10, 1],\n",
       " [1, 5, 2, 1],\n",
       " [1, 5, 2, 1],\n",
       " [1, 5, 9, 1],\n",
       " [1, 4, 8, 1],\n",
       " [1, 4, 6, 1],\n",
       " [1, 4, 0, 1],\n",
       " [1, 4, 10, 1],\n",
       " [1, 4, 5, 1],\n",
       " [1, 4, 10, 1],\n",
       " [1, 4, 9, 1],\n",
       " [1, 4, 1, 1],\n",
       " [1, 4, 4, 1],\n",
       " [1, 4, 4, 1],\n",
       " [1, 4, 0, 1],\n",
       " [1, 4, 3, 1],\n",
       " [1, 4, 1, 1],\n",
       " [1, 4, 3, 1],\n",
       " [1, 4, 2, 1],\n",
       " [1, 4, 4, 1],\n",
       " [1, 4, 4, 1],\n",
       " [1, 4, 8, 1],\n",
       " [1, 4, 2, 1],\n",
       " [1, 4, 4, 1],\n",
       " [1, 3, 2, 1],\n",
       " [1, 3, 6, 1],\n",
       " [1, 3, 4, 1],\n",
       " [1, 3, 7, 1],\n",
       " [1, 3, 4, 1],\n",
       " [1, 3, 1, 1],\n",
       " [1, 3, 10, 1],\n",
       " [1, 3, 3, 1],\n",
       " [1, 3, 4, 1],\n",
       " [1, 3, 7, 1],\n",
       " [1, 3, 5, 1],\n",
       " [1, 3, 6, 1],\n",
       " [1, 3, 1, 1],\n",
       " [1, 3, 6, 1],\n",
       " [1, 3, 10, 1],\n",
       " [1, 3, 2, 1],\n",
       " [1, 3, 4, 1],\n",
       " [1, 3, 2, 1],\n",
       " [1, 3, 1, 1],\n",
       " [1, 3, 5, 1],\n",
       " [1, 2, 4, 1],\n",
       " [1, 2, 2, 1],\n",
       " [1, 2, 8, 1],\n",
       " [1, 2, 3, 1],\n",
       " [1, 2, 1, 1],\n",
       " [1, 2, 9, 1],\n",
       " [1, 2, 10, 1],\n",
       " [1, 2, 9, 1],\n",
       " [1, 2, 4, 1],\n",
       " [1, 2, 5, 1],\n",
       " [1, 2, 0, 1],\n",
       " [1, 2, 9, 1],\n",
       " [1, 2, 9, 1],\n",
       " [1, 2, 0, 1],\n",
       " [1, 2, 1, 1],\n",
       " [1, 2, 1, 1],\n",
       " [1, 2, 4, 1],\n",
       " [1, 1, 0, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 5, 1],\n",
       " [1, 1, 3, 1],\n",
       " [1, 1, 10, 1],\n",
       " [1, 1, 6, 1],\n",
       " [1, 1, 0, 1],\n",
       " [1, 1, 8, 1],\n",
       " [1, 1, 6, 1],\n",
       " [1, 1, 4, 1],\n",
       " [1, 1, 9, 1],\n",
       " [1, 1, 9, 1],\n",
       " [1, 1, 4, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 9, 1],\n",
       " [1, 1, 0, 1],\n",
       " [1, 1, 8, 1],\n",
       " [1, 1, 6, 1],\n",
       " [1, 1, 1, 1],\n",
       " [1, 1, 1, 1],\n",
       " [1, 1, 5, 1]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68.77, 51.25, 52.08, 38.36, 44.54, 57.13, 51.4, 41.42, 31.22, 34.76, 54.01, 38.79, 47.59, 49.1, 27.66, 41.03, 36.73, 48.65, 28.12, 46.62, 35.57, 32.98, 35, 26.07, 23.77, 39.73, 40.57, 31.65, 31.21, 36.32, 20.45, 21.93, 26.02, 27.34, 23.49, 46.94, 30.5, 33.8, 24.23, 21.4, 27.94, 32.24, 40.57, 25.07, 19.42, 22.39, 18.42, 46.96, 23.72, 26.41, 26.97, 36.76, 40.32, 35.02, 29.47, 30.2, 31, 38.11, 38.18, 36.31, 21.03, 30.86, 36.07, 28.66, 29.08, 37.28, 15.28, 24.17, 22.31, 30.17, 25.53, 19.85, 35.37, 44.6, 17.23, 13.47, 26.33, 35.02, 32.09, 24.81, 19.33, 28.77, 24.26, 31.98, 25.73, 24.86, 16.28, 34.51, 15.23, 39.72, 40.8, 26.06, 35.76, 34.76, 16.13, 44.04, 18.03, 19.65, 32.62, 35.59, 39.43, 14.18, 35.24, 40.13, 41.82, 35.45, 36.07, 43.67, 24.61, 20.9, 21.9, 18.79, 27.61, 27.21, 26.61, 29.77, 20.59, 27.53, 13.82, 33.2, 25, 33.1, 36.65, 18.63, 14.87, 22.2, 36.81, 25.53, 24.62, 26.25, 18.21, 28.08, 19.42, 29.79, 32.8, 35.99, 28.32, 27.79, 35.88, 29.06, 36.28, 14.1, 36.63, 37.49, 26.9, 18.58, 38.48, 24.48, 18.95, 33.55, 14.24, 29.04, 32.51, 25.63, 22.22, 19, 32.73, 15.16, 13.9, 27.2, 32.01, 29.27, 33, 13.74, 20.42, 27.32, 18.23, 35.35, 28.48, 9.08, 24.62, 20.12, 35.26, 19.92, 31.02, 16.49, 12.16, 30.7, 31.22, 34.65, 13.13, 27.51, 33.2, 31.57, 14.1, 33.42, 17.44, 10.12, 24.42, 9.82, 23.39, 30.93, 15.03, 21.67, 31.09, 33.29, 22.61, 26.89, 23.48, 8.38, 27.81, 32.35, 23.84]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List\n",
    "\n",
    "# Each vector contains 4 values. A constant term = 1, number of friends, number of work hours, has a phD\n",
    "inputs: List[List[float]] = [[1.,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
    "\n",
    "display(inputs)\n",
    "\n",
    "daily_minutes = [\n",
    "    1,68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,\n",
    "    48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,\n",
    "    46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,\n",
    "    35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,\n",
    "    19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,\n",
    "    39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,\n",
    "    43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,\n",
    "    25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,\n",
    "    38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,\n",
    "    18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,\n",
    "    33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84\n",
    "]\n",
    "num_friends = [\n",
    "    100.0,49,41,40,25,21,21,19,19,18,18,16,15,15,15,15,14,14,13,13,13,13,12,12,11,10,10,10,10,10,10,\n",
    "    10,10,10,10,10,10,10,10,10,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,8,8,8,8,8,8,8,8,8,8,8,8,8,7,7,7,7,\n",
    "    7,7,7,7,7,7,7,7,7,7,7,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n",
    "    5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,\n",
    "    2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "outlier = num_friends.index(100)\n",
    "daily_minutes_good = [y for i, y in enumerate(daily_minutes) if i != outlier]\n",
    "print(daily_minutes_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./dsfs/mlr.py\n",
    "from typing import Tuple, List\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "from dsfs.vector import Vector, dot_product, add\n",
    "from dsfs.matrix import Matrix, vector_mean\n",
    "from dsfs.gradients import gradient_step\n",
    "from dsfs.lr import total_sum_of_squares\n",
    "\n",
    "\n",
    "def predict(xs: Vector, beta: Vector) -> float:\n",
    "    assert xs[0] == 1, \"The first element of xs must be 1\"\n",
    "    return dot_product(xs, beta)\n",
    "\n",
    "\n",
    "def error(xs: Vector, y: float, beta: Vector) -> float:\n",
    "    return predict(xs, beta) - y\n",
    "\n",
    "\n",
    "def squared_error(xs: Vector, y: float, beta: Vector) -> float:\n",
    "    return error(xs, y, beta) ** 2\n",
    "\n",
    "xs = [1,2,3]\n",
    "y = 30\n",
    "beta =[4,4,4]\n",
    "\n",
    "assert predict(xs, beta) == sum([4,8,12])\n",
    "assert error(xs, y, beta ) == -6\n",
    "assert squared_error(xs, y, beta) == 36\n",
    "\n",
    "\n",
    "def sqerror_gradient(xs: Vector, y:float, beta: Vector) -> Vector:\n",
    "    err = error(xs, y, beta)\n",
    "    return [2 * err * x_i for x_i in xs]\n",
    "\n",
    "assert sqerror_gradient(xs, y, beta) == [-12, -24, -36]\n",
    "\n",
    "def least_squares_fit(\n",
    "        xs: Matrix,\n",
    "        ys: Vector,\n",
    "        learning_rate: float = 0.001,\n",
    "        num_steps: int = 1000,\n",
    "        batch_size:int = 1,\n",
    "        sqerror_gradient_fn = sqerror_gradient\n",
    "):\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "    for _ in tqdm.trange(num_steps, desc=\"Least squares fit\"):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start: start+batch_size]\n",
    "            batch_ys = ys[start: start+batch_size]\n",
    "            gradient = vector_mean(\n",
    "                [sqerror_gradient_fn(x, y, guess) for x,y in zip(batch_xs, batch_ys)]\n",
    "            )\n",
    "            guess = gradient_step(guess, gradient, -learning_rate)\n",
    "    return guess\n",
    "\n",
    "\n",
    "def multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n",
    "    sum_of_squared_errors = sum(error(x, y, beta) ** 2 for x,y in zip(xs,ys))\n",
    "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(ys)\n",
    "\n",
    "\n",
    "def estimate_sample_beta(pairs: List[Tuple[Vector, float]]):\n",
    "    x_sample, y_sample = zip(*pairs)\n",
    "    beta = least_squares_fit(\n",
    "        xs=x_sample,\n",
    "        ys=y_sample,\n",
    "        learning_rate=0.001,\n",
    "        num_steps=5000,\n",
    "        batch_size=25\n",
    "    )\n",
    "    return beta\n",
    "\n",
    "\n",
    "def ridge_penalty(beta: Vector, alpha: float) -> float:\n",
    "    \"\"\"The larger alpha is, the larger the penalty is\"\"\"\n",
    "    return alpha * dot_product(beta[1:], beta[1:])\n",
    "\n",
    "\n",
    "def squared_error_ridge(\n",
    "        xs: Vector,\n",
    "        y: float,\n",
    "        beta: Vector,\n",
    "        alpha: float) -> float:\n",
    "    return error(xs, y, beta) ** 2 + ridge_penalty(beta, alpha)\n",
    "\n",
    "\n",
    "def ridge_penalty_gradient(beta: Vector, alpha: float) -> Vector:\n",
    "    return [0.] + [2 * alpha * beta_j for beta_j in beta[1:]]\n",
    "\n",
    "\n",
    "def sqerror_ridge_gradient(xs: Vector, y: float, beta: Vector, alpha: float) -> Vector:\n",
    "    return add(sqerror_gradient(xs, y, beta), ridge_penalty_gradient(beta, alpha))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1760.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "beta = least_squares_fit(\n",
    "    inputs, \n",
    "    daily_minutes_good, \n",
    "    learning_rate=0.001,\n",
    "    num_steps=5000,\n",
    "    batch_size=25\n",
    ")\n",
    "contants, num_friends_weight, work_hours_per_day_weight, has_phD_weight = beta\n",
    "# daily_minutes = contants + num_friends_weight * num_friends + work_hours_per_day_weight * work_hours_per_day + has_phD_weight * has_phD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30.514795945185586, 0.9748274277323267, -1.8506912934343662, 0.91407780744768'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"{contants}, {num_friends_weight}, {work_hours_per_day_weight}, {has_phD_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6799849346187969"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_r_squared(inputs, daily_minutes_good, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./dsfs/bootstap.py\n",
    "import random\n",
    "from typing import TypeVar, Callable\n",
    "\n",
    "\n",
    "X = TypeVar('X')\n",
    "Stat = TypeVar('Stat')\n",
    "\n",
    "\n",
    "def bootstrap_sample(data: List[X]) -> List[X]:\n",
    "    \"\"\" Returns a list of len(data) samples from data with replacement \"\"\"\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "\n",
    "def bootstrap_stastistic(data: List[X], stats_fn: Callable[[List[X]], Stat], num_samples: int) -> List[Stat]:\n",
    "    return [stats_fn(bootstrap_sample(data)) for _ in range(num_samples)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "far_from_100 = (\n",
    "    [99.5 + random.random()] + \n",
    "    [random.random() for _ in range(50)] +\n",
    "    [200 + random.random() for _ in range(50)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.08980118353116 99.72046053686783\n",
      "0.2681667535372883 99.98963225091724\n"
     ]
    }
   ],
   "source": [
    "from dsfs.stats import median, standard_deviation\n",
    "print(median(close_to_100), median(far_from_100))\n",
    "print(standard_deviation(close_to_100), standard_deviation(far_from_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028832812995301355 94.4214229181966\n"
     ]
    }
   ],
   "source": [
    "median_close = bootstrap_stastistic(close_to_100, median, 100)\n",
    "median_far = bootstrap_stastistic(far_from_100, median, 100)\n",
    "print(standard_deviation(median_close), standard_deviation(median_far))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1756.44it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1752.09it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1758.55it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1777.20it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1763.28it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1775.09it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1769.58it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1770.85it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1766.64it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1764.15it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1756.55it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1750.52it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1751.86it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1757.18it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1750.23it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1719.65it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1685.97it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1740.40it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1772.01it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1750.61it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1736.75it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1748.09it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1750.08it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:03<00:00, 1657.06it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:03<00:00, 1606.38it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1734.51it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1757.46it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1770.12it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1759.71it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1748.52it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1747.33it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1741.23it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:03<00:00, 1639.34it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1758.50it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1718.92it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1688.61it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1753.82it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1757.32it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1752.39it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1704.30it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1749.60it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1731.91it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1746.84it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1745.94it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1755.61it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1739.40it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1762.94it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1733.91it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1753.18it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1761.06it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1751.57it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1760.47it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1768.22it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1751.81it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1751.20it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1736.21it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1756.00it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1756.41it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1765.37it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1744.93it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1754.99it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1749.08it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1762.30it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1751.30it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1704.37it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:03<00:00, 1650.40it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1696.64it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1711.60it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1728.08it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1768.52it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1774.35it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1744.74it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1726.88it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1753.02it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1740.95it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1722.40it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1701.21it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:03<00:00, 1660.99it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1746.88it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1726.20it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1697.95it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1693.07it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1729.84it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1742.78it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1729.48it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1695.92it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1698.62it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1697.25it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1693.42it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1701.63it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1724.22it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1706.15it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1703.69it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1715.57it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1725.22it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1726.12it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1745.86it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1757.17it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1750.28it/s]\n",
      "Least squares fit: 100%|██████████| 5000/5000 [00:02<00:00, 1742.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# This will run a 100 fits on sample data to evaluate the quality of the betas. (be patient)\n",
    "bootstrap_betas = bootstrap_stastistic(\n",
    "    list(zip(inputs, daily_minutes_good)),\n",
    "    estimate_sample_beta,\n",
    "    100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.514795945185586, 0.9748274277323267, -1.8506912934343662, 0.91407780744768]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1.3236332751698134,\n",
       " 0.08779582186482865,\n",
       " 0.1522636521885064,\n",
       " 1.1084268610186834]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bootstrap_std_errors = [\n",
    "    standard_deviation([_beta[i] for _beta in bootstrap_betas]) for i in range(4)]\n",
    "display(beta)\n",
    "display(bootstrap_std_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.4095633599001194]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dsfs.probs import normal_cdf, two_sided_p_value\n",
    "\n",
    "display(\n",
    "    [\n",
    "        two_sided_p_value(beta[i], sigma=bootstrap_std_errors[i]) \n",
    "        for i in range(4)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the p-value for has PhD is greater than 0.4, we could conclude that it is more random than meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1038.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alpha:0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[30.514270168416875,\n",
       " 0.9748555246861115,\n",
       " -1.850672026233393,\n",
       " 0.9144873400391185]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.211617337785668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6799848827962514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1024.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alpha:0.1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[30.801522297155426,\n",
       " 0.9507227673492153,\n",
       " -1.8331427966237475,\n",
       " 0.5384471323396428]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.554211607494469"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6796563695922921"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1014.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alpha:1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[30.649808578631028,\n",
       " 0.8971525641333581,\n",
       " -1.676799532439464,\n",
       " 0.10444589861663219]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.6274483410580998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6748564624405934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Least squares fit: 100%|██████████| 5000/5000 [00:04<00:00, 1023.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alpha:10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[28.30708308025664,\n",
       " 0.6726275942984854,\n",
       " -0.9045499907700505,\n",
       " -0.0052131931011540865]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.2706657437961764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5604040113888359"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "for alpha in [0, 0.1, 1, 10]:\n",
    "    sqerror_gradient_fn_alpha = partial(sqerror_ridge_gradient, alpha=alpha)\n",
    "    beta_ridged = least_squares_fit(\n",
    "        inputs, \n",
    "        daily_minutes_good, \n",
    "        learning_rate=0.001, \n",
    "        num_steps=5000, \n",
    "        batch_size=25, \n",
    "        sqerror_gradient_fn=sqerror_gradient_fn_alpha\n",
    "    )\n",
    "    display(f\"alpha:{alpha}\")\n",
    "    display(beta_ridged)\n",
    "    display(dot_product(beta_ridged[1:], beta_ridged[1:]))\n",
    "    display(multiple_r_squared(inputs, daily_minutes_good, beta=beta_ridged))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, as we increased `alpha`, the coefficients are getting smaller (has_phd is almost 0.) but the goodness of fit is getting worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
